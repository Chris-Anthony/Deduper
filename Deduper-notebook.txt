----------------------
|       Deduper      |
----------------------

Christian Chua
Bioninformatics 610/624
Fall 2020

----------------------
| Table of Contents  |
----------------------

Date        Description
10/19/2020  Pseudocode
10/22/2020  Pseudocode on mate pair error correction - incomplete
10/23/2020  Pseudocode on warning messages; included examples
10/25/2020  Resolved rolling window problem (and mate pair correction)

----------------------
|  10/19-25/2020     |
----------------------

Problem:
    Given a sam file of uniquely mapped reads, we are tasked with removing all PCR duplicates and retaining a single copy of each duplicate.
    It is specified that we have restrictions on memory and the entire sam file cannot be loaded into memory.
    Furthermore, it is asked that we allow for single-end reads or paired-end reads (if possible) and randomers or 96 umis in the parameters.
    We have to account for soft clipping. 

Description:
    The following pseudocode is for a Reference Based PCR Duplicate Removal tool written in Python 3 ("chua_deduper.py") that addresses the problem described above.
    In order for this script to run correctly, the sam file will need to be sorted by the leftmost coordinates using Samtools (http://www.htslib.org/doc/samtools-sort.html).
    
    This script will take arguments from the user to determine which of the duplicate reads to keep in the output file. Required arguments are the file path 
    and name of the file. Optional arguments include whether the file is zipped, the file path of the output file, whether the file is paired end, and whether
    the file contains UMIs. The defaults are unzipped, current directory, single-end reads, and randomers, respectively. The name of the output file is 
    hardcoded to be the name of the file appended with "_deduped". Error correction can be turned on. There are several mutual exclusive options for retaining 
    the duplicate read - the read with the best average per base quality score, a random read, or the nth read seen. 

    The script determines if a read is a duplicate if its position (group/chromosome number, leftmost position, and strandedness) and UMI/randomer barcode are
    the same. Soft clipping is taken into account by default by looking at the CIGAR string. Reads are considered within the same locus if the next read seen is within 
    a certain number of bases. As scripts goes through each line of the input SAM file, it stores all reads in a list and choses the best duplicate read to output 
    by the aforementioned methods. This script requires that the SAM files be sorted using Samtool sort function before piping into the script. 

    Examples of the expected input and outputs for each function are shown after their pseudocode.

Psuedocode: chua_deduper.py

import re
import gzip

def argparse():
    '''allow for user input from command line'''

    -f, --file: required arg, absolute file path
    -s, --sampleID: required arg, SAM file 
    -h, --help: by default is true, prints a USEFUL help message (e.g. help="string of text" in argparse object argument)

    optional arguments:
    -z, --zipped: optional arg, specify whether the SAM file is zipped (default is unzipped) <- can make this agnostic of user - if the script sees gz in filename
    -o, --output: optional arg, output path for the "dedupered" SAM file (default is current directory)
    -p, --paired: optional arg, designates file is paired end (default is single-end reads)
    -u, --umi: optional arg, designates file containing the list of UMIs (default is randomers)
    -c, --correct: optional arg, tries to errorcorrect (default is true, must set to false)
    -t, --threshold: optional arg, sets the number of bases the next read has to be within to be counted within the same locus; best practice is the insert size length (default is 350)

    optional mutual exclusive arguments to define which read to output: (use group = parser.add_mutually_exclusive_group(); see argparse doc)
    default is the 1st duplicated read seen
    -b, --best: optional arg, returns the duplicate read with the best average per base quality score
    -r, --random: optional arg, return a random duplicate read
    -n, --number: optional arg, returns the nth seen duplicate read; requires a positive non-zero integer input.
                If integer is greater than number of duplicate reads, returns the last read seen.

    1. print warning message to standard error if user did not include required arguments or included an incorrect combination of arguments (e.g. -b and -r)

    return argparse arguments

def UMIcorrect(str)->str:
    ```takes a barcodes and attempts to find match in the global variable UMI_list.```

    1. use list comprehension, try to match barcode to each item in UMI_list 
        a. use regex allowing for one mismatch (e.g. re.fullmatch("(barcode){e<=1}", UMI_list[x])
        b. if match object is true, 
            return item in list
        c. else, return false

    NOTE: This function may be depreciated depending on complexity in order to minimize the amount of function.
    NOTE: Need to consider processing time.  Essentially this is a searching algorithm. Is there a better way to do this? BOWTIE method! 

def checkCIGAR(str, int)->int:
    ```takes the CIGAR string and leftmost position and corrects the position if there has been soft clipping```

    1. if there is an "S" at the beginning of the CIGAR string (compare to first element of re.findall list)
        a. use regular expressions to pull the number in front of the S
        b. subtract that number from the leftmost position and make that the new position
    2. else do nothing

    return updated leftmost position

    Example 1 Inputs: 1S61M4S, 100
    Example 1 Output: 99

    Example 2 Inputs: 65M1S, 100
    Example 2 Output: 100

def ErrorCorrection(dict)->dict:
    ```goes through the dictionary of records. If any of the keys contain an N, use its paired read to error correct```

    1. Iterate through the dictionary's keys
    2. If barcode within the key contains a N,
        a. search through the keys for a matched object with one allowed mismatch in the barcode 
        b. if there is one and only one matched object, 
            i. append the old key's value (list of records) to the found key's value <- order of records was not retained from original file
            ii. remove old key-value pair
    3. if paired is true,
        c. search through the again keys for a matched object with one allowed mismatch in the barcode, but of different strandedness
            i. change the N to the correct base using the matched object (the paired read)
    4. if there are no matches, remove key-value pair

    return updated dictionary without any N's in barcodes

    Example 1 Input: {CCCGGN-123456-read1:[record1, record2, record6], CCCGGG-123456-read1:[record3, record4, record5]}
    Example 1 Output: {CCCGGG-123456-read1:[record3, record4, record5, record1, record2, record6]}

    Example 2 Input: {CCCGGN-123456-read1:[record1, record2, record6], CCCGGG-123456-read2:[record3, record4, record5]}
    Example 2 Output: {CCCGGG-123456-read1:[record1, record2, record6], CCCGGG-123456-read2:[record3, record4, record5]}

def bestRead(dict)->dict:
    ```iterates through each list and chooses the read with the highest average per base quality score```

    1. create a variable "max_quality" and set it equal to zero
    2. create a variable "best_record" and set it equal to the string "empty"
    3. for key in dictionary, look at each list one by one
        a. for each list, iterate through its elements, which are records:
            i. create a variable "avg_quality" and set it equal to zero
            ii. pull out the quality sequence in column 11
            iii. iterate through each character in quality sequence
                1. convert the letter to a phred score <- which conversion to use?***
                2. add value to "avg_quality"
            iv. divide "avg_quality" by the length of the quality sequence (replace "avg_quality" value with that value)
                1. if "avg_quality" is greater than "max_quality",
                    a. set "max_quality" equal to "avg_quality"
                    b. set "best_record" equal to the current record.
                2. else, do nothing
            v. repeat above steps for each element in current list
            vi. lastly, replace the entire list with the "best_record"
    4. repeat above for each key-value pair

    return updated "records" dictionary whose values are now lists of one element, the best read

    Example 1 Input: dictionary(barcode1:[record1, record2, record3], barcode2:[record4], barcode3:[record5, record6, etc.])
    Example 1 Output: dictionary(barcode1:[record1], barcode2:[record4], barcode3:[record6])

    Example 2 Input: NOTE, it has been formated with whitespace for readability
        (AACGCCAT: 
            [NS500451:154:HWKTMBGXX:1:11101:94095:71756:AACGCCAT	0	2	76875967	36	15M470N56M	*	0	0	GTGGGATGAGGCGCTCTTTTATATTGAGTTGGGCTGTGCAGGAGTCTTTTCCCACTTCATTGACGGCTEST	6<EEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU	XS:A:-	XG:Z:A
            , NS500451:154:HWKTMBGXX:1:11101:69992:67325:AACGCCAT	0	2	76875967	36	15M470N56M	*	0	0	GTGGGATGAGGCGCTCTTTTATATTGAGTTGGGCTGTGCAGGAGTCTTTTCCCACTTCATTGACGGCGTAG	6<EEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEA	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU	XS:A:-	XG:Z:A]
        , ATCGAACC:
            [NS500451:154:HWKTMBGXX:1:11101:10266:1114:ATCGAACC	0	2	76875957	36	25M470N46M	*	0	0	GTGAAACTCGGTGGGATGAGGCGCTCTTTTATATTGAGTTGGGCTGTGCAGGAGTCTTTTCCCACTTCATT	6<EAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEAEEEEEEE	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU	XS:A:-	XG:Z:A]
        , GTGATGTC:
            [NS500451:154:HWKTMBGXX:1:11101:5571:1221:GTGATGTC	0	2	76901561	36	71M	*	0	0	TTCCAGGTACACAAAAGTCTTCTGAGTAAACAACCTGTACTTTTTGCTACTTCGGATCTGCTTCTTGTCTT	6AEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEA	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU
            , NS500451:154:HWKTMBGXX:1:11101:86637:67646:GTGATGTC	0	2	76901561	36	71M	*	0	0	TTCCAGGTACACAAAAGTCTTCTGAGTAAACAACCTGTACTTTTTGCTACTTCGGATCTGCTTCTTGTEST	6AEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU])
    Example 2 Output:
        (AACGCCAT: 
            [NS500451:154:HWKTMBGXX:1:11101:94095:71756:AACGCCAT	0	2	76875967	36	15M470N56M	*	0	0	GTGGGATGAGGCGCTCTTTTATATTGAGTTGGGCTGTGCAGGAGTCTTTTCCCACTTCATTGACGGCTEST	6<EEEEEEEEEEEEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU	XS:A:-	XG:Z:A]
            , ATCGAACC:
            [NS500451:154:HWKTMBGXX:1:11101:10266:1114:ATCGAACC	0	2	76875957	36	25M470N46M	*	0	0	GTGAAACTCGGTGGGATGAGGCGCTCTTTTATATTGAGTTGGGCTGTGCAGGAGTCTTTTCCCACTTCATT	6<EAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEAEEEEEEE	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU	XS:A:-	XG:Z:A]
        , GTGATGTC:
            [NS500451:154:HWKTMBGXX:1:11101:5571:1221:GTGATGTC	0	2	76901561	36	71M	*	0	0	TTCCAGGTACACAAAAGTCTTCTGAGTAAACAACCTGTACTTTTTGCTACTTCGGATCTGCTTCTTGTEST	6AEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE	MD:Z:71	NH:i:1	HI:i:1	NM:i:0	SM:i:36	XQ:i:40	X2:i:0	XO:Z:UU])

def randomRead(dict)->dict:
    ```iterates through each list and choses a random read from each list```

    1. for key in dictionary, look at each list one by one
        a. for each list, generate a random integer "i" between 0 and the length of list minus one using randrange(from this number, to this number) inclusive;
        b. replace the entire list with the "i"th element of that list
    2. repeat above fo each key-value pair

    return updated "records" dictionary whose values are now lists of one element, a random read

    Example Input: dictionary(barcode1:[record1, record2, record3, ..., record100])
    Example Output: dictionary(barcode1:[record at the ith position])
    NOTE: testing this function would require looking at the random number generated and ensuring it matches the ith element in that list.

def readNum(int, dict)->dict:
    ```chooses the (n-1)th element in list and returns it. If n is greater than the length of the list, returns the last element```

    1. for key in dictionary, look at each list one by one
        a. for each list, 
            1. if n is greater than the length of the list, set the whole list equal to the last element. n was user supplied
            2. else, set the whole list equal to the (n-1)th element.
    2. repeat the above for each key-value pair

    return updated "records" dictionary whos values are now lists of one element, the nth or last element of the original list.

    Example Input: n=28, dictionary(barcode1:[record1, record2, record3, ..., record100])
    Example Output: dictionary(barcode1:[record at the 27th element])

def main(): <- this is the main function, it calls other functions as needed
    '''Takes in a SAM file, iterates record by record, 
    and separates records into output files based on barcode pair/quality'''

    1. takes argparse arguments and set them as variables
        in = input file path
        fh = file name
        
        See argparse function for more details on the below variables.
            zipped = FALSE; replaced with TRUE
            out = FALSE; replaced with output file path
            paired = FALSE; replaced with TRUE <- **** why would I need this?***
            umi = FALSE; replaced with file path and file name designating UMIs
            best = FALSE; replaced with TRUE
            random = FALSE; replaced with TRUE
            number = FALSE; replaced with integer
            correct = TRUE; replaced with FALSE for no error correction
            threshold = 350; can be replaced with any integer 

    NOTE: 
    Use boolean logic to determine or not to run pieces of codes
    try, except statments to handle errors -> print to standard error if does not work

    2. if UMI is true:
        a. open UMI file at path specified
        b. store barcodes as a list "UMI_list" (as a global variable)
        c. used in part 3.e.ii.2.a

    3. Read SAM file - indentation demarks if/else statements or loops
        a. open the file:
            i. if zipped is TRUE, use gzip module. 
        b. open an output file to which to write (do not use append):
            i. if out is TRUE, write to that specified location
            ii. Output a properly formatted SAM file with “_deduped” appended to the filename
        c. read the input file line by line
        d. copy @ headers to output file
        e. store every record within the same locus (reads within a certain number of bases of each other) in a "dictionary of lists" using a loop:
            i. create an empty dictionary "records"
            ii. for the 1st record line, pull the barcode info from column 1:
                1. pull out positional information and store them as variables
                    a. RNAME = col 3 of record - scaffold 
                    b. POS = col 4 of record
                        i. call checkCIGAR function to check for soft clipping and "correct" the leftmost position
                    c. FLAG = col 2 of record - strandedness
                2. pull the barcode information from column 1
                    a. if UMI is true:
                        i. if barcode is not in UMI_list,
                            1. attempt to error correct, call UMIcorrect() 
                            2. if cannot fix error or N>=2, exit loop and proceed to next record line
                    b. else, if UMI is false (then it is a randomer):
                        i. if N>=2, exit loop and proceed to next record line
                        ii. additional error correction once dictionary is filled
                    c. the barcode, leftmost position and strandedness will become a key for the dictionary (e.g. AACTAG-1658463218-read1)
                    d. intilize an empty list for records[key]
                3. store the record as the 0th element of the list in records[key]
            iii. for the every subsequent line, if RNAME, POS (+ threshold), and **FLAG** are the same, add to the dictionary.
                1. for POS,
                    a. we are calling the checkCIGAR function to check for soft clipping and "correct" the leftmost position
                    b. we accept reads within a certain number of bases from the last read (set by threshold)
                2. for FLAG, we need to use the "bitwise and" to compare whether the records have the same strandedness
                    (e.g. (A&stranded)&(B&stranded) <- returns true if same strand)
                3. Correct the barcodes as specified in 3.e.ii.2.a/b and create a key using the left-most position and strandedness as in 3.e.ii.2.c
                4. if the key already exists,
                    a. add the record to list in records[key] as the next element
                5. if the key does NOT exist,
                    a. store key in the dictionary "records" with an empty list as its value
                    b. add the record to list in records[key] as the 0th element
            iv. if the next line is not within a certain number of bases (set by threshold) from the last read's position
                1. If UMI is false, 
                    a. attempt to correct all keys with an N by calling ErrorCorrection function
                        - if paired is true, there is an additional error correction step
                2. analyze the current "records" dictionary and choose one record from each list in the dictionary to write to the output file depending on the initial user inputs 
                    (see below)
                    - if best is TRUE, call bestRead function.
                    - elif random is TRUE, call randomRead function.
                    - elif number is TRUE, call readNum function.
                3. for each key in "records", write to the output file the lists followed by newline character
                4. reset the "records" variable to an empty dictionary
                5. analyze the new line as described in 3.e.ii onwards
            v. repeat above steps for all records in the file

    Example Input: A properly formated input sam file. See Github repo (https://github.com/Chris-Anthony/Deduper)
    Example Output: A properly formated expected output sam file. See Github repo (https://github.com/Chris-Anthony/Deduper)

Additional functionality?
    1. analysis of the quality scores
    2. print the number of times we have seen a particular UMI/randomer? 
    3. can include another outfile for rejected reads

    01011001 01101111 01110101 00100000 01100001 01110010 01100101 00100000 01100001 
    01101100 01101100 00100000 01100001 01101101 01100001 01111010 01101001 01101110 
    01100111 00100001 00100000 00111100 00110011 00100000 01000011 01101000 01110010 
    01101001 01110011